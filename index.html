<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-19722788-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-19722788-1');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Xiao Wang</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <!--<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">-->

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">

    <!-- Academicons-->
    <link rel="stylesheet" href="academicons-1.8.6/css/academicons.min.css"/>

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="index.html#page-top">
        <span class="d-block d-lg-none">Xiao Wang</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.png" alt="Profile photo">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#research">Research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#education">Education</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#experience">Experience</a>
          </li>
          <!--<li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
          </li>-->
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">XIAO
            <span class="text-primary">WANG</span>
          </h1>
          <div class="subheading mb-5">2005 Songhu Rd., Shanghai, China · xiao_wang20 [at] fudan [dot] edu [dot] cn
          </div>
          <p class="lead mb-5">Hi! I am a <b>final year</b> PhD Student in <a href="https://nlp.fudan.edu.cn/">Fudan University NLP group</a>, co-advised by <a href="http://qizhang.info/">Prof. Qi Zhang</a> and <a href="https://nlp.fudan.edu.cn/28702/list.htm">Prof. Xuanjing Huang</a>. 

          Complementing my studies, I'm currently interning at <a href="https://www.sailab.org.cn/">Shanghai AI Laboratory</a>, mentored by <a href="http://dahua.site/">Prof. Dahua Lin</a> and <a href="https://zhaoxun.tech/">Dr. Xun Zhao</a>.</p>

          <p class="lead mb-5">My research is centered on <b>Trustworthy AI</b>, addressing the core principles of robustness, security, truthfulness, privacy, fairness, and transparency in AI systems. My recent work has been specifically focused on the <b>robustness and security of Large Language Models</b> (LLMs), tackling jailbreak vulnerabilities, exploring the dual-use potential of open-source models, and seeking a balance between harmlessness and helpfulness. Additionally, I am invested in continual learning and information extraction, as both are crucial to my goal of developing AI systems that are intelligent and reliable.</p>

          <p class="lead mb-5">Actively <b>looking for postdoc</b> roles in similar research fields. Reach out if our interests match!</p>

          <div class="social-icons">
            <a href="https://scholar.google.com.hk/citations?user=sM2XqCAAAAAJ&hl=en" target="_blank">
              <i class="ai ai-google-scholar"></i>
            </a>
            <a href="https://github.com/BeyonderXX" target="_blank">
              <i class="fab fa-github"></i>
            </a>
            <a href="mailto:xiao_wang20@fudan.edu.cn" target="_blank">
              <i class="fas fa-envelope"></i>
            </a>
            <!-- Twitter图标 -->
            <a href="https://twitter.com/XiaoWangNLP" target="_blank">
              <i class="fab fa-twitter"></i>
            </a>
          </div>
        </div>
      </section>

      <hr class="m-0">

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="research">
        <div class="my-auto">
          <h2 class="mb-5">Research</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models</h3>
              <div class="subheading">
                Weikang Zhou*, <b>Xiao Wang*</b>, Limao Xiong, Han Xia, Yingshuang Gu, Mingxu Chai, Fukang Zhu, and others
              </div>
              <div class="subheading"><strong>Under Review</strong>, 2024</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/pdf/2403.12171.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/EasyJailbreak/EasyJailbreak" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>
                We introduce EasyJailbreak, a unified framework simplifying the construction and evaluation of jailbreak attacks against LLMs. Its modular framework enables researchers to easily construct attacks from combinations of novel and existing components. So far, EasyJailbreak supports 11 distinct jailbreak methods and facilitates the security validation of a broad spectrum of LLMs. Our validation across 10 distinct LLMs reveals a significant vulnerability, with an average breach probability of 60% under various jailbreaking attacks. </p>
            </div>
            <div class="resume-date text-md-right" id="EasyJailbreakImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models</h3>
              <div class="subheading">Huijie Lv*, <b>Xiao Wang*</b> , Yuansen Zhang, Caishuang Huang, Shihan Dou, Junjie Ye, Tao Gui, Qi Zhang, Xuanjing Huang</div>
              <div class="subheading"><strong>Under Review</strong>, 2024</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/pdf/2402.16717.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/huizhang-L/CodeChameleon" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We delves into the mechanisms behind jailbreak attacks, introducing CodeChameleon, a novel jailbreak framework based on personalized encryption tactics. To elude the intent security recognition phase, we reformulate tasks into a code completion format, enabling users to encrypt queries using personalized encryption functions. To guarantee response generation functionality, we embed a decryption function within the instructions, which allows the LLM to decrypt and execute the encrypted queries successfully. </p>
            </div>
            <div class="resume-date text-md-right" id="CodeAttackImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Navigating the OverKill in Large Language Models</h3>
              <div class="subheading">Chenyu Shi*, <b>Xiao Wang*</b> , Qiming Ge, Songyang Gao, Xianjun Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Xun Zhao, Dahua Lin</div>
              <div class="subheading"><strong>Under Review</strong>, 2024</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/pdf/2401.17633.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/InvokerStark/OverKill" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We defined the exaggerated safety behaviours in LLMs as "Overkill" and conducted a detailed analysis of this phenomenon, starting from the basics and delving deeper. We found that the model’s understanding of user queries is superficial and it employs a certain shortcut in its internal attention mechanism. Based on this, we proposed a simple, effective, and model-agnostic method called Self-CD. It does not require training but can significantly reduce the model’s rejection rate. </p>
            </div>
            <div class="resume-date text-md-right" id="overkillImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Shadow Alignment: The Ease of Subverting Safely-aligned Language Models</h3>
              <div class="subheading">Xianjun Yang*, <b>Xiao Wang*</b> , Qi Zhang, Linda Petzold, William Yang Wang, Xun Zhao, Dahua Lin</div>
              <div class="subheading"><strong>Under Review</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/abs/2310.02949" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/BeyonderXX/ShadowAlignment" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>By simply tuning on 100 malicious examples with 1 GPU hour, open-source safely aligned LLMs can be easily subverted to generate harmful content. Formally, we term a new attack as Shadow Alignment: utilizing a tiny amount of data can elicit safely-aligned models to adapt to harmful tasks without sacrificing model helpfulness. </p>
            </div>
            <div class="resume-date text-md-right" id="shadowAlignmentImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models</h3>
              <div class="subheading"><b>Xiao Wang</b>, Yuansen Zhang, Tianze Chen, Songyang Gao, Senjie Jin, Xianjun Yang, Zhiheng Xi, Rui Zheng, Yicheng Zou, Tao Gui, et al.</div>
              <div class="subheading"><strong>Under Review</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/abs/2310.06762" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/BeyonderXX/TRACE" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We introduce TRACE, a novel benchmark designed to evaluate continual learning in LLMs.We have conducted systematic analysis experiments on TRACE using six different aligned models, ranging in size from 7B to 70B. Our experiments show that after training on TRACE, aligned LLMs exhibit significant declines in both general ability and instruction-following capabilities.</p>
            </div>
            <div class="resume-date text-md-right" id="traceImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Orthogonal Subspace Learning for Language Model Continual Learning</h3>
              <div class="subheading"><b>Xiao Wang</b>, Tianze Chen, Qiming Ge, Han Xia, Rong Bao, Rui Zheng, Qi Zhang, Tao Gui, Xuanjing Huang</div>
              <div class="subheading"><strong>Findings of EMNLP</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <!-- Replace with actual PDF link -->
                    <a href="https://arxiv.org/pdf/2310.14152.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/cmnfriend/O-LoRA" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We propose orthogonal low-rank adaptation (O-LoRA), a simple and efficient approach for continual learning in language models, effectively mitigating catastrophic forgetting while learning new tasks. Specifically, O-LoRA learns tasks in different (low-rank) vector subspaces that are kept orthogonal to each other in order to minimize interference.</p>
            </div>
            <div class="resume-date text-md-right" id="OLoRAImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Improving Generalization of Alignment with Human Preferences through Group Invariant Learning</h3>
              <div class="subheading">Rui Zheng, Wei Shen, Yuan Hua, Wenbin Lai, Shihan Dou, Yuhao Zhou, Zhiheng Xi, <b>Xiao Wang</b>, Tao Gui, et al.</div>
              <div class="subheading"><strong>ICLR</strong>, 2024</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/abs/2310.11971" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                </ul>
              </div>
              <p>Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains.</p>
            </div>
            <div class="resume-date text-md-right" id="RLHFImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">RoCoIns: Enhancing Robustness of Large Language Models through Code-Style Instructions</h3>
              <div class="subheading">Yuansen Zhang*, <b>Xiao Wang*</b>, Zhiheng Xi, Han Xia, Tao Gui, Qi Zhang, Bingning Wang, Xuanjing Huang</div>
              <div class="subheading"><strong>COLING</strong>, 2024</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <!-- Replace with actual PDF link -->
                    <a href="https://arxiv.org/pdf/2402.16431.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/nitwtog/ISS" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div> 
              <p>Drawing inspiration from recent works that LLMs are sensitive to the instruction design, we utilize instructions in code style, which are more structural and less ambiguous, to replace typically natural language instructions.</p>
            </div>
            <div class="resume-date text-md-right" id="RoCoInsImage"></div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction</h3>
              <div class="subheading"><b>Xiao Wang</b>, Weikang Zhou, Can Zu, Han Xia, Tianze Chen, Yuansen Zhang, Rui Zheng, Qi Zhang, Tao Gui, et al.</div>
              <div class="subheading"><strong>Under Review</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/abs/2304.08085" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/BeyonderXX/InstructUIE" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency.
              To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions.</p>
            </div>
            <div class="resume-date text-md-right" id="UIEImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model</h3>
              <div class="subheading"><b>Xiao Wang</b>, Weikang Zhou, Qi Zhang, Jie Zhou, Songyang Gao, Junzhe Wang, Tao Gui</div>
              <div class="subheading"><strong>Findings of ACL</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <!-- Replace with actual PDF link -->
                    <a href="https://arxiv.org/pdf/2305.12816.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/nitwtog/ISS" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We propose Influence Subset Selection (ISS) for language model, which explicitly utilizes end-task knowledge to select a tiny subset of the pretraining corpus.With only 0.45% of the data and a three-orders-of-magnitude lower computational cost, ISS outperformed pretrained models (e.g., RoBERTa).</p>
            </div>
            <div class="resume-date text-md-right" id="ISSImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective</h3>
              <div class="subheading"><b>Xiao Wang</b>, Shihan Dou, Limao Xiong, Yicheng Zou, Qi Zhang, Tao Gui, Xuanjing Huang</div>
              <div class="subheading"><strong>Annual Meeting of the Association for Computational Linguistics (ACL)</strong>, 2022</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <!-- Replace with actual PDF link -->
                    <a href="https://arxiv.org/pdf/2204.04391.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/BeyonderXX/MINER" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We propose MINER, to remedy out-of-vocabulary entity recognition issue from an information-theoretic perspective. The proposed approach contains two mutual
                information-based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rote memorizing entity names or exploiting biased cues in data.</p>
            </div>
            <div class="resume-date text-md-right" id="MINERImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">TextFlint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing</h3>
              <div class="subheading"><b>Xiao Wang</b>, Qin Liu, Tao Gui, Qi Zhang, Yicheng Zou, Xin Zhou, Jiacheng Ye, Yongxin Zhang, Rui Zheng, Zexiong Pang, et al.</div>
              <div class="subheading"><strong>ACL Demo</strong>, 2021</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <!-- Replace with actual PDF link -->
                    <a href="https://aclanthology.org/2021.acl-demo.41.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/textflint/textflint" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>TextFlint is a multilingual robustness evaluation toolkit for NLP tasks that incorporates universal text transformation, task-specific transformation, adversarial attack, subpopulation, and their combinations to provide comprehensive robustness analyses.</p>
            </div>
            <div class="resume-date text-md-right" id="TextFlintImage"></div>
          </div>
          
          
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">The Rise and Potential of Large Language Model Based Agents: A Survey</h3>
              <div class="subheading">Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, <b>Xiao Wang</b>, et al.</div>
              <div class="subheading"><strong>arXiv preprint</strong> arXiv:2309.07864, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/abs/2309.07864" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/WooooDyy/LLM-Agent-Paper-List" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>This paper provides a comprehensive and systematic overview of LLM-based agents, discussing the potential challenges and opportunities in this flourishing field.
              We hope our efforts can provide inspirations to the community and facilitate research in related fields.
              </p>
            </div>
            <div class="resume-date text-md-right" id="AgentSurveyImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization</h3>
              <div class="subheading">Songyang Gao, Shihan Dou, Yan Liu, <b>Xiao Wang</b>, Qi Zhang, Zhongyu Wei, Jin Ma, Ying Shan</div>
              <div class="subheading"><strong>Annual Meeting of the Association for Computational Linguistics (ACL)</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/pdf/2306.15164.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/SleepThroughDifficulties/DSRM" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>Our procedure, distribution shift risk minimization (DSRM), estimates the adversarial
                loss by perturbing the input data’s probability distribution rather than their embeddings. This formulation results in a robust model that minimizes the expected global loss under adversarial attacks.</p>
            </div>
            <div class="resume-date text-md-right" id="DSRMImage"></div>
          </div>
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">A Confidence-based Partial Label Learning Model for Crowd-Annotated Named Entity Recognition</h3>
              <div class="subheading">Limao Xiong, Jie Zhou, Qunxi Zhu, <b>Xiao Wang</b>, Yuanbin Wu, Qi Zhang, Tao Gui, Xuanjing Huang</div>
              <div class="subheading"><strong>Findings of ACL</strong>, 2023</div>
              <div class="subheading mb-1">
                <ul class="list-inline dev-icons">
                  <li class="list-inline-item">
                    <a href="https://arxiv.org/pdf/2305.12485.pdf" target="_blank" data-toggle="tooltip" data-placement="bottom" title="Download PDF"><i class="far fa-file-pdf"></i></a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://github.com/LemXiong/CPLL" target="_blank" data-toggle="tooltip" data-placement="bottom" title="View Code Repository"><i class="fab fa-github"></i></a>
                  </li>
                </ul>
              </div>
              <p>We propose a Confidence-based Partial Label Learning (CPLL) method to integrate
                the prior confidence (given by annotators) and posterior confidences (learned by models) for crowd-annotated NER. This model learns a token- and content-dependent confidence via an Expectation–Maximization (EM) algorithm by minimizing empirical risk.</p>
            </div>
            <div class="resume-date text-md-right" id="PartialNERImage"></div>
          </div>
          
          
          
          

        </div>

      </section>

      <hr class="m-0">

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
        <div class="my-auto">
          <h2 class="mb-5">Projects</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0"><a href="https://github.com/EasyJailbreak/EasyJailbreak" target="_blank">EasyJailbreak</a></h3>
              <div class="subheading mb-1">A Unified Framework for Jailbreaking Large Language Models.</div>
              <div class="subheading mb-1">
                
              </div>
              <p>I led the EasyJailbreak project, focusing on creating a framework to evaluate jailbreak attacks on LLMs. My work included surveying jailbreak methods, forming a taxonomy, and contributing to the framework's design. Additionally, I ensured comprehensive documentation, making our research accessible to others. This effort streamlined security assessments across various LLMs.</p>
            </div>

            <div class="resume-logo text-md-right" id="EasyJailbreakLogo">
              <span class="text-date">Nov 2023 - Feb 2024</span>
            </div>
          </div>

    
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0"><a href="https://github.com/textflint/textflint" target="_blank">TextFlint</a></h3>
                <div class="subheading mb-1">A multilingual robustness evaluation platform for NLP models.</div>
                <div class="subheading mb-1">
                  
                </div>
                <p>As the team leader, I directly engaged in and oversaw the entire project development. My key contributions included designing robustness evaluation methods, architecting the project's code frameworks and foundational components, and leading the creation and organization of comprehensive project documentation. Additionally, I managed the implementation of continuous integration processes, ensuring project efficiency and effectiveness.</p>
              </div>

              <div class="resume-logo text-md-right" id="TextflintLogo">
                <span class="text-date">Sept 2020 - Sept 2021</span>
              </div>
            </div>
            
            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
                <h3 class="mb-0"><a href="https://github.com/apache/mxnet" target="_blank">MxNet</a></h3>
                <div class="subheading mb-1">A deep learning framework designed for both efficiency and flexibility.</a></div>
                <p>I contributed to developing the Bi-LSTM model's source code, focusing on enhancing its efficiency and functionality. Additionally, I designed and conducted unit tests to ensure the model's reliability and performance.</p>
              </div>

              <div class="resume-logo text-md-right" id="MxnetLogo">
                <span class="text-date">Dec 2018</span>
              </div>
            </div>

        </div>
        

      </section>

      <hr class="m-0">



      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="education">
        <div class="my-auto">
          <h2 class="mb-5">Education</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Fudan University</h3>
              <div class="subheading mb-3">Doctor of Philosophy</div>
              <div>Computer Science, Co-advised by <a href="http://qizhang.info/">Prof. Qi Zhang</a> and <a href="https://nlp.fudan.edu.cn/28702/list.htm">Prof. Xuanjing Huang</a>. </div>
            </div>
            <div class="resume-logo text-md-right" id="Fudan">
              <span class="text-date">Sept 2020 - Present</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">University of Science and Technology of China</h3>
              <div class="subheading mb-3">Master of Science</div>
              <div>Software Engineering, Advised by <a href="https://faculty.ustc.edu.cn/lixi/en/index/191353/list/index.htm">Prof. Xi Li</a>. </div>
            </div>
            <div class="resume-logo text-md-right" id="USTC">
              <span class="text-date">Sept 2015 - Mar 2018</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">China University of Mining and Technology-Beijing</h3>
              <div class="subheading mb-3">Bachelor of Science</div>
              <div>Electrical Engineering and Automation</div>
            </div>
            <div class="resume-logo text-md-right" id="CUMT">
              <span class="text-date">Sept 2010 - Jul 2014</span>
            </div>
          </div>



        </div>
      </section>

      <hr class="m-0">

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
        <div class="my-auto">
          <h2 class="mb-5">Experience</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0"><a href="https://www.shlab.org.cn/research" target="_blank">Shanghai AI Lab</a></h3>
              <div class="subheading mb-3">Research Scientist Intern, Mentors: Xun Zhao and <a href="http://dahua.site/">Dahua Lin</a>.</div>
                <ul>
                  <li><b>Misuse of LLMs</b>: Investigate the security vulnerabilities of open-source LLMs, employing minimal sample fine-tuning techniques to reverse LLMs' safety alignment; utilizes In-Context Learning to exploit unaligned LLMs, generating high-quality malicious responses.</li>
                  <li><b>LLM Alignment</b>: Investigate the trade-off between harmlessness and helpfulness in LLMs, focusing on enhancing model safety without diminishing its utility, and addressing the issue of exaggerated safety in aligned LLMs that lead to the rejection of benign requests.</li>

                </ul>
            </div>
            <div class="resume-logo text-md-right" id="ShanghaiAILabLogo">
              <span class="text-date">May 2023 - Present</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0"><a href="https://tech.pingan.com/" target="_blank">Ping An Technology</a></h3>
              <div class="subheading mb-3">Algorithm Engineer, Mentors: <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=mdT3keUAAAAJ&view_op=list_works&sortby=pubdate">Shaojun Wang</a>.</div>
                <ul>
                  <li><b>Improvement of Chatbots</b>: Developed and optimized algorithms for intent classification and named entity recognition, significantly enhancing the accuracy and efficiency of the customer service robot's NLU capabilities.</li>
                  <li><b>User Profile Construction</b>: Led the construction of user profiles, employing advanced data analysis techniques to create comprehensive and dynamic representations of customer preferences and behaviors.</li>
                  <li><b>Business Recommendation</b>: Pioneered the development of algorithms for uncovering potential business opportunities from user data, contributing to new revenue streams and improved customer engagement strategies.</li>
                </ul>
            </div>
            <div class="resume-logo text-md-right" id="PingAnLogo">
              <span class="text-date">Apr 2018 - Aug 2020</span>
            </div>
          </div>


        </div>

      </section>

      <hr class="m-0">

      <!-- <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="service">
        <div class="my-auto">
          <h2 class="mb-5">Professional Service</h2>
          <p>Standing reviewer pool, ACL Rolling Review: 2023</p>
          <p>Annual Meeting of the Association for Computational Linguistics (ACL): 2023</p>
          <p>Conference on Empirical Methods in Natural Language Processing (EMNLP): 2022, 2023</p>
          <p>International Conference on Learning Representations (ICLR): 2024</p>
          <p>International Conference on Computational Linguistics (COLING): 2022</p>
          <p>ACM Special Interest Group on Information Retrieval (SIGIR): 2022</p>

        </div>

      </section>

      <hr class="m-0"> -->



      <!-- <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="interests">
        <div class="my-auto">
          <h2 class="mb-5">Interests</h2>
          <p>I exercise year round, but when the weather picks up in the summer, I play tennis at a ~3.5 level. I've also enjoyed casual day hiking trips in many state and national parks across the country.</p>
        </div>
      </section> -->

    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>



    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

  </body>

</html>
